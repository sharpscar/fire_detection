import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import argparse
import os
from tqdm import tqdm
import copy

#  GPU ì „ìš© ê°•ì œ ì„¤ì •
if not torch.cuda.is_available():
    raise RuntimeError("CUDA GPUê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì´ ì½”ë“œëŠ” GPUì—ì„œë§Œ ì‹¤í–‰ë©ë‹ˆë‹¤.")

device = torch.device("cuda")
print(f"GPU ì‚¬ìš© ì¤€ë¹„ ì™„ë£Œ: {torch.cuda.get_device_name(device)}")

# í”„ë¡œì íŠ¸ ë‚´ ë‹¤ë¥¸ ëª¨ë“ˆ ì„í¬íŠ¸
from model import create_fire_detection_model
from dataset import get_dataloaders

def train_model(data_dir, model_save_dir, num_epochs=25, batch_size=32, learning_rate=0.001):
    """
    GPU ì „ìš©: ëª¨ë¸ í•™ìŠµ ë©”ì¸ í•¨ìˆ˜
    """
    # 1. ì¥ì¹˜ ì„¤ì • (GPUë§Œ ì‚¬ìš©)
    # ì „ì—­ìœ¼ë¡œ deviceê°€ ì„¤ì •ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ì¤‘ë³µ ì²´í¬ë¥¼ ì œê±°í•©ë‹ˆë‹¤.
    print(f"Using device: {device}")

    # 2. ë°ì´í„° ë¡œë” ì¤€ë¹„
    print("Loading data...")
    train_loader, val_loader, class_names = get_dataloaders(data_dir, batch_size)
    print(f"Classes found: {class_names}")
    print(f"Train dataset size: {len(train_loader.dataset)} images")
    print(f"Validation dataset size: {len(val_loader.dataset)} images")

    # 3. ëª¨ë¸, ì†ì‹¤ í•¨ìˆ˜, ì˜µí‹°ë§ˆì´ì € ì¤€ë¹„
    print("Initializing model...")
    model = create_fire_detection_model(num_classes=len(class_names))
    model = model.to(device)

    # ì†ì‹¤ í•¨ìˆ˜ ë° ì˜µí‹°ë§ˆì´ì €ëŠ” ëª¨ë¸ì´ deviceë¡œ ì´ë™ëœ í›„ì— ì •ì˜í•©ë‹ˆë‹¤.
    criterion = nn.CrossEntropyLoss()
    params_to_update = model.fc.parameters()
    optimizer = optim.Adam(params_to_update, lr=learning_rate)

    # 3.1. ì €ì¥ëœ ëª¨ë¸ ë¡œë”© (ìˆë‹¤ë©´)
    model_path = os.path.join(model_save_dir, "best_fire_detection_model.pth")
    if os.path.exists(model_path):
        print(f"ì €ì¥ëœ ëª¨ë¸ì—ì„œ ì¬ê°œ: {model_path}")
        model.load_state_dict(torch.load(model_path, map_location=device))
        best_model_wts = copy.deepcopy(model.state_dict())

        print("Performing initial validation pass...")
        model.eval()
        initial_running_loss = 0.0
        initial_running_corrects = 0
        with torch.no_grad():
            for inputs, labels in val_loader:
                inputs = inputs.to(device)
                labels = labels.to(device)
                outputs = model(inputs)
                _, preds = torch.max(outputs, 1)
                loss = criterion(outputs, labels)
                initial_running_loss += loss.item() * inputs.size(0)
                initial_running_corrects += torch.sum(preds == labels.data)
        best_val_loss = initial_running_loss / len(val_loader.dataset)
        initial_acc = initial_running_corrects.double() / len(val_loader.dataset)
        print(f"Initial Validation Loss: {best_val_loss:.4f} Acc: {initial_acc:.4f}")
        model.train()
    else:
        print("ì €ì¥ëœ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìƒˆë¡­ê²Œ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.")
        best_val_loss = float('inf')
        best_model_wts = None

    # 4. í•™ìŠµ ë£¨í”„

    for epoch in range(num_epochs):
        print("-" * 30)
        print(f"ğŸ“… Epoch {epoch+1}/{num_epochs}")

        for phase in ['train', 'val']:
            model.train() if phase == 'train' else model.eval()
            dataloader = train_loader if phase == 'train' else val_loader

            running_loss = 0.0
            running_corrects = 0

            progress_bar = tqdm(dataloader, desc=f"{phase.capitalize()} Phase")
            for inputs, labels in progress_bar:
                inputs = inputs.to(device)
                labels = labels.to(device)

                optimizer.zero_grad()

                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    _, preds = torch.max(outputs, 1)
                    loss = criterion(outputs, labels)

                    if phase == 'train':
                        loss.backward()
                        optimizer.step()

                running_loss += loss.item() * inputs.size(0)
                running_corrects += torch.sum(preds == labels)

                progress_bar.set_postfix(loss=loss.item())

            epoch_loss = running_loss / len(dataloader.dataset)
            epoch_acc = running_corrects.double() / len(dataloader.dataset)

            print(f"ğŸ“Š {phase.capitalize()} Loss: {epoch_loss:.4f} | Acc: {epoch_acc:.4f}")

            if phase == 'val' and epoch_loss < best_val_loss:
                print(f" ê²€ì¦ ì†ì‹¤ ê°ì†Œ: {best_val_loss:.4f} â†’ {epoch_loss:.4f}, ëª¨ë¸ ì €ì¥")
                best_val_loss = epoch_loss
                best_model_wts = copy.deepcopy(model.state_dict())

    if best_model_wts:
        os.makedirs(model_save_dir, exist_ok=True)
        save_path = os.path.join(model_save_dir, "best_fire_detection_model.pth")
        torch.save(best_model_wts, save_path)
        print(f"âœ… ìµœì¢… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {save_path}")
    else:
        print("í•™ìŠµ ê°œì„  ì—†ìŒ. ëª¨ë¸ ì €ì¥ ì•ˆ ë¨.")

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description="í™”ì¬ ê°ì§€ ëª¨ë¸ í•™ìŠµ (GPU ì „ìš©)")
    base_dir = os.path.dirname(os.path.abspath(__file__))

    parser.add_argument("--data-dir", type=str, default=os.path.join(base_dir, "../data/train"),
                        help="í•™ìŠµ ë°ì´í„° ë””ë ‰í† ë¦¬")
    parser.add_argument("--model-save-dir", type=str, default=os.path.join(base_dir, "../models"),
                        help="ëª¨ë¸ ì €ì¥ ë””ë ‰í† ë¦¬")
    parser.add_argument("--num-epochs", type=int, default=25, help="í•™ìŠµ ë°˜ë³µ íšŸìˆ˜")
    parser.add_argument("--batch-size", type=int, default=32, help="ë°°ì¹˜ í¬ê¸°")
    parser.add_argument("--learning-rate", type=float, default=0.001, help="í•™ìŠµë¥ ")

    args = parser.parse_args()

    train_model(
        data_dir=args.data_dir,
        model_save_dir=args.model_save_dir,
        num_epochs=args.num_epochs,
        batch_size=args.batch_size,
        learning_rate=args.learning_rate
    )
